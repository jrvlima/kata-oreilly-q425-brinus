/**
 * AI & Analytics for MobilityCorp
 *
 * This file defines the AI-powered systems that address MobilityCorp's business challenges:
 * 1. Computer Vision Verification (photo-based operational verification)
 * 2. Geo-Fence Enforcement (safety and compliance)
 *
 * NOTE: Generic RAG/Vector DB removed - we use specific implementations for CV verification
 * (see model.cv_verification.c4)
 */

model {
    extend mobiltiy_corp {

        ai_systems = group 'AI Systems' {

            style {
                color mobilitycorp-purple
                opacity 20%
                border dashed
            }

            description 'AI-powered systems for operational verification, safety, and compliance'

            // Reference to CV Verification System (defined in model.cv_verification.c4)
            // - Docking verification (bikes/scooters)
            // - Damage detection (before/after comparison)
            // - Return photo verification (cars/vans)
            // Uses: Qdrant (RAG) + OpenAI/Anthropic/Azure (multimodal LLMs)

            // Geo-Fence Enforcement (Edge AI - not cloud-based)
            // - Restricted zone enforcement
            // - Speed-limited zone control
            // - Wrong-way detection on one-way streets
            // Runs on vehicle edge processors (Raspberry Pi), not in cloud

            description 'RAG and semantic search built from Gold-layer summaries & facts. Reused by Ops, Support, Planning.'
            
            vector_db = database 'Vector DB' {
                description "Vector DB - Semantic search and embeddings storage for AI-powered knowledge retrieval"

                link ../fleeting_ai/vector-db.md 'Full Documentation'

                technology 'Qdrant'
            }
            
            rag_api = container 'RAG API' {
                description "RAG API - Retrieval-Augmented Generation for grounded AI assistance with citations"

                link ../fleeting_ai/rag-api.md 'Full Documentation'

                technology 'FastAPI + LlamaIndex/LangChain + LiteLLM/Bedrock'

                style {
                    icon tech:python 
                }

                cv_decision_endpoint = component 'CV Decision Endpoint' {
                    technology 'FastAPI route: POST /cv/decision'
                    description 'Provider-abstracted multimodal prompt; temperature=0; JSON schema output; circuit breakers; prompt versioning'

                    // Optional few-shot retrieval for grounding
                    -> vector_db 'Similar-case Retrieval' {
                        title 'Few-shot'
                        description 'Retrieve K verified examples (bay/model/condition) to ground the LLM'
                    }

                    // Uses the same provider gateway
                    -> litellm_proxy 'Invokes providers' { title 'Vision/Multimodal' }
                }

                -> vector_db 'Retrieves context for LLM' {
                        title 'Semantic Retrieval'
                        description 'RAG API performs nearest-neighbor search to retrieve most relevant context documents for LLM prompts.'
                        technology 'Hybrid Search (Dense + Sparse) • Qdrant'
                    }
                -> gold_marts 'Queries curated facts' {
                        title 'Fact Retrieval'
                        description 'Structured SQL queries to curated marts provide validated, explainable business facts complementing semantic retrieval.'
                        technology 'SQL • Postgres / ClickHouse'
                    }
                -> read_model_db 'Reads current projections' {
                        title 'Operational Snapshot Access'
                        description 'RAG agents query CQRS read models for up-to-date operational data (e.g., vehicle availability, user sessions).'
                        technology 'PostgreSQL • REST / GraphQL'
                    }

                -> litellm_proxy 'Sends prompts to LLMs' {
                        title 'LLM Invocation'
                        description 'RAG API constructs prompts with retrieved context and sends them to LiteLLM Proxy for processing by various LLM providers.'
                        technology 'REST API • JSON'
                    }
            }

            

            // DAG that prepares embeddings from Gold
            embed_pipeline = container 'Embedding Pipeline' {
                description "Embedding Pipeline - Transform Gold data into semantic vectors for RAG retrieval"

                link ../fleeting_ai/embedding-pipeline.md 'Full Documentation'

                technology 'Airflow task / Streaming job'

                style {
                    icon tech:python 
                }

                -> vector_db 'Upserts vectors' {
                        title 'Vector Store Population'
                        description 'Embeddings and metadata are persisted for semantic search and RAG pipelines.'
                        technology 'Qdrant / Pinecone | REST / gRPC API'
                    }

                -> litellm_proxy 'Generates embeddings' {
                        title 'Embedding Generation'
                        description 'Text data from Gold is converted into vector embeddings using various LLM embedding models via LiteLLM Proxy.'
                        technology 'REST API • JSON'
                }
            }
        }
    }
}
