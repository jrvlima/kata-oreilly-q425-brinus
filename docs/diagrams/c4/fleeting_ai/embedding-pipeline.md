# Embedding Pipeline - Transform Gold data into semantic vectors for RAG retrieval

## Context

MobilityCorp generates structured operational data (Gold Marts) that needs to be searchable via natural language. Requirements:

- Convert tabular metrics into natural language summaries ("Berlin had 42 eBikes rented on 2024-10-15")
- Generate embeddings for incident reports, maintenance logs, ops summaries
- Keep vector embeddings in sync with Gold layer updates (daily refresh)
- Attach metadata (date, location, tags) for filtered retrieval
- Track provenance (which Gold table/row generated each embedding)

## Problem

Raw Gold tables are query-optimized but not LLM/vector-search-ready:

1. **Format Mismatch**: Vector DBs need text chunks + embeddings; Gold has rows with 50+ numeric/categorical columns
2. **Semantic Gap**: Column name `avg_battery_pct` means nothing to LLM; needs expansion to "average battery percentage was 67%"
3. **Freshness**: Gold updates daily; embeddings lag by 24 hours if not automated
4. **Provenance Loss**: Without metadata, RAG retrieves embedding but can't cite source table/row for verification
5. **Chunking Strategy**: Long incident reports (5000 words) exceed embedding model limits (512 tokens); need smart splitting

## Solution Justification

Dedicated embedding pipeline automates text generation + vectorization with quality controls:

- **Text Synthesis**: dbt models generate natural language summaries from Gold facts (SQL → prose)
- **Batch Embedding**: Sentence transformers encode text in batches (100 docs/sec); GPU-accelerated for scale
- **Metadata Tagging**: Attach structured filters (location_id, date, tags) to each embedding for hybrid search
- **Incremental Updates**: Process only new/updated Gold rows since last run (timestamp-based)
- **Quality Checks**: Validate embedding dimensions, detect outliers (cosine similarity to corpus mean)

## Use Cases

### 1. Daily Ops Summary Embeddings
- **Source**: Gold `daily_ops_summary_text` table (generated by dbt)
- **Example Row**: "2024-10-15, Berlin, 'High eBike demand (120% of average), 5 vehicles required battery swap, weather: rainy 12°C'"
- **Pipeline**:
  1. Airflow DAG runs nightly (2am)
  2. Fetch new summaries (where date > last_run_date)
  3. Encode with `all-MiniLM-L6-v2` (384-dim embeddings)
  4. Upsert to Qdrant with metadata: {date, location_id, tags: ['high_demand', 'battery'], source: 'daily_ops_summary'}
- **Benefit**: RAG can answer "What happened in Berlin last week?" by retrieving top-k similar summaries

### 2. Incident Report Embeddings
- **Source**: Gold `incident_reports` table (maintenance logs, customer complaints, system alerts)
- **Example**: "Vehicle VEH-123 battery drain 40%/hour (expected 10%/hour). User reported 'sluggish acceleration'. Diagnosed: faulty battery cell. Replaced battery pack."
- **Pipeline**:
  1. Chunk long reports (>512 tokens) into overlapping 256-token segments
  2. Embed each chunk with multilingual model (`paraphrase-multilingual-MiniLM-L12-v2`)
  3. Store with metadata: {vehicle_id, incident_type, resolution_status, language}
- **Benefit**: Technicians search "battery drain issue" → retrieve similar past incidents with resolution steps

### 3. Maintenance Playbook Embeddings
- **Source**: Markdown docs in Git repo (standard operating procedures, troubleshooting guides)
- **Example**: "## Charging Station Offline\n1. Check breaker panel\n2. Restart controller (hold button 10sec)\n3. Contact vendor if still offline"
- **Pipeline**:
  1. CI/CD triggers embedding job on Git commit (new/updated playbooks)
  2. Parse markdown sections (headers = natural chunk boundaries)
  3. Embed with `text-embedding-ada-002` (OpenAI) for best semantic quality
  4. Store with metadata: {playbook_name, version, last_updated}
- **Benefit**: RAG retrieves exact procedure when ops asks "How to fix charging station?"

### 4. KPI Metric Narratives
- **Source**: Gold `kpi_summary_monthly` (executive metrics)
- **Example Row**: {month: '2024-10', total_revenue: 450000, booking_count: 12000, customer_ltv: 85}
- **Narrative Generation** (dbt model):
  ```sql
  SELECT CONCAT(
    'In ', month, ', MobilityCorp generated €', total_revenue,
    ' revenue from ', booking_count, ' bookings. ',
    'Customer LTV increased to €', customer_ltv, '.'
  ) AS summary_text
  ```
- **Pipeline**: Embed narratives → Store with metadata: {month, kpi_category}
- **Benefit**: Execs ask "What was Q3 revenue trend?" → RAG retrieves relevant months with context

### 5. Anomaly Detection Alerts
- **Source**: Silver `alerts` topic (Kafka) → Gold `alert_history` table
- **Example**: "ALERT: Berlin location - Vehicle availability dropped to 15% at 08:30 (expected 60%). Possible causes: demand spike, battery management issue."
- **Pipeline**:
  1. Stream alerts to Gold (hourly micro-batch)
  2. Embed alert text with metadata: {location, alert_type, severity, timestamp}
  3. Real-time upsert to Qdrant (sub-minute latency)
- **Benefit**: RAG answers "Recent availability alerts in Berlin?" with fresh data

## Technology Choice

**Selected**: Airflow + Sentence Transformers + Qdrant API

**Rationale**:
- **Airflow**: Orchestrates multi-step pipeline (fetch Gold → generate text → embed → upsert)
  - Incremental processing with XCom state tracking (last_processed_date)
  - Retry logic for transient Qdrant connection failures
- **Sentence Transformers**: Python library for state-of-the-art embedding models
  - Supports 100+ pretrained models (multilingual, domain-specific)
  - GPU acceleration (CUDA) for 10x throughput
  - Batch encoding API (process 1000 docs in 5 seconds)
- **Alternative - Streaming**: Kafka → Flink for real-time embeddings (sub-minute latency)
  - Use case: Embed incident reports as they're created (not 24-hour delay)
- **EU Compliance**: Self-hosted Sentence Transformers + Qdrant; no external API calls
